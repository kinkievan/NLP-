{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 分割\n",
    "本章目標\n",
    "1) 範例如何利用nltk 的function將句子做斷句。斷句會遇到什麼問題?\n",
    "2) 斷詞範例，程式是如何運作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 斷句練習 sent_tokenize\n",
    "\n",
    "1)  讀入一篇文章\n",
    "2)  再利用nltk.sent_tokenize 做斷句\n",
    "3)  查看斷句結果\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[The Man Who Was Thursday by G. K. Chesterton 1908]\\n'\n",
      " '\\n'\n",
      " 'To Edmund Clerihew Bentley\\n'\n",
      " '\\n'\n",
      " 'A cloud was on the mind of men, and wailing went the weather,\\n'\n",
      " 'Yea, a sick cloud upon the soul when we were boys together.',\n",
      " 'Science announced nonentity and art admired decay;\\n'\n",
      " 'The world was old and ended: but you and I were gay;\\n'\n",
      " 'Round us in antic order their crippled vices came--\\n'\n",
      " 'Lust that had lost its laughter, fear that had lost its shame.',\n",
      " 'Like the white lock of Whistler, that lit our aimless gloom,\\n'\n",
      " 'Men showed their own white feather as proudly as a plume.',\n",
      " 'Life was a fly that faded, and death a drone that stung;\\n'\n",
      " 'The world was very old indeed when you and I were young.',\n",
      " 'They twisted even decent sin to shapes not to be named:\\n'\n",
      " 'Men were ashamed of honour; but we were not ashamed.',\n",
      " 'Weak if we were and foolish, not thus we failed, not thus;\\n'\n",
      " 'When that black Baal blocked the heavens he had no hymns from us\\n'\n",
      " 'Children we were--our forts of sand were even as weak as eve,\\n'\n",
      " 'High as they went we piled them up to break that bitter sea.',\n",
      " 'Fools as we were in motley, all jangling and absurd,\\n'\n",
      " 'When all church bells were silent our cap and beds were heard.',\n",
      " 'Not all unhelped we held the fort, our tiny flags unfurled;\\n'\n",
      " 'Some giants laboured in that cloud to lift it from the world.',\n",
      " 'I find again the book we found, I feel the hour that flings\\n'\n",
      " 'Far out of fish-shaped Paumanok some cry of cleaner things;\\n'\n",
      " 'And the Green Carnation withered, as in forest fires that pass,\\n'\n",
      " 'Roared in the wind of all the world ten million leaves of grass;\\n'\n",
      " 'Or sane and sweet and sudden as a bird sings in the rain--\\n'\n",
      " 'Truth out of Tusitala spoke and pleasure out of pain.',\n",
      " 'Yea, cool and clear and sudden as a bird sings in the grey,\\n'\n",
      " 'Dunedin to Samoa spoke, and darkness unto day.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pprint\n",
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "\n",
    "sents = nltk.sent_tokenize(text)\n",
    "\n",
    "pprint.pprint(sents[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筆紀\n",
    "1) raw()可以查看語料庫的原始內容\n",
    "2) sent_tokenize 做句子的斷句\n",
    "3) pprint 更簡解的方式列印"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  斷句有會遇到的問題\n",
    "\n",
    "1) 有時候英文字的縮寫會有句號.會被做斷句。被當成句子的結尾\n",
    "2) 另外也會有斷的不正確的地方。在第6章會再說明斷句"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 斷詞 Word Segmentation\n",
    "\n",
    "本節目標\n",
    "1)  斷詞是如何去做斷詞的動作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "a.\t\tdoyouseethekitty\n",
    "\n",
    "b.\t\tseethedoggy\n",
    "\n",
    "c.\t\tdoyoulikethekitty\n",
    "\n",
    "d.\t\tlikethedogg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定義一個斷詞function , 可以依自已的方式做斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment(text, segs):\n",
    "    words = []\n",
    "    last = 0\n",
    "    for i in range(len(segs)):\n",
    "        if segs[i] == '1':\n",
    "            words.append(text[last:i+1])\n",
    "            last = i+1\n",
    "    words.append(text[last:])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"doyouseethekitty seethedoggy doyoulikethekitty likethedoggy\"\n",
    "\n",
    "seg1 = \"0000000000000001 00000000001 00000000000000001 00000000000\"\n",
    "\n",
    "segment(text, seg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筆記\n",
    "\n",
    "1) text 為要做的斷詞的文字\n",
    "\n",
    "2) seg  為斷詞標記。對應斷詞的文字的標記，1就是要斷 。\n",
    "\n",
    "3) 一開始先從seg 下手\n",
    "0000000000000001 00000000001 0000000000000000100000000000\n",
    "\n",
    "4) 發現第seg[15]為1\n",
    "\n",
    "5) 接者text 第一個斷詞長度是 16 \n",
    "\n",
    "6) 所以第一個斷詞是text[0:16]\n",
    "\n",
    "7) 下一次開始斷詞text[16:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 設定一個評分function ，來比較斷詞的好壞. 分數越小的代表斷詞越好\n",
    "\n",
    "\n",
    "# 分數 =  斷詞結果list的長度+不重覆的單字的長度\n",
    "\n",
    "# 例: 不重覆單字越長or 越多 代表斷的不好。等於有斷跟沒斷一樣\n",
    "\n",
    "\n",
    "# 程式說明\n",
    "\n",
    "斷詞1：　\n",
    "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
    "\n",
    "\n",
    "長度4 +不重覆的單字長度 60\n",
    "\n",
    "\n",
    "斷詞2：　['do,you,see,the,kitty,see,the,doggy,do,you,like,the,kitty,like,the,doggy']\n",
    "\n",
    "\n",
    "長度16+不重覆的單字長度32\n",
    "\n",
    "\n",
    "斷詞3：\n",
    "['doyou,see,thekitt,y,see,thedogg,y,doyou,like,thekitt,y,like,thedogg,y']  \n",
    "\n",
    "\n",
    "長度14+不重覆的單字長度33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(text, segs):\n",
    "    words = segment(text, segs)\n",
    "    text_size = len(words)\n",
    "    lexicon_size = sum(len(word) + 1 for word in set(words))\n",
    "    return text_size + lexicon_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "48\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n",
    "\n",
    "seg3 = \"0000100100000011001000000110000100010000001100010000001\"\n",
    "\n",
    "print(evaluate(text, seg1))\n",
    "print(evaluate(text, seg2))\n",
    "print(evaluate(text, seg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "4\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "words = segment(text, seg1)\n",
    "print(words)\n",
    "text_size = len(words)\n",
    "print(text_size)\n",
    "\n",
    "lexicon_size = sum(len(word) + 1 for word in set(words))\n",
    "print(lexicon_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  利用程式來計算最好的斷詞方式。達到最小分數，就是最好的的斷詞。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def flip(segs, pos):\n",
    "    return segs[:pos] + str(1-int(segs[pos])) + segs[pos+1:]\n",
    "\n",
    "def flip_n(segs, n):\n",
    "    for i in range(n):\n",
    "        segs = flip(segs, randint(0, len(segs)-1))\n",
    "    return segs\n",
    "\n",
    "def anneal(text, segs, iterations, cooling_rate):\n",
    "    temperature = 55\n",
    "    while 55 > 0.5:\n",
    "        best_segs, best = segs, evaluate(text, segs)\n",
    "        for i in range(iterations):\n",
    "            guess = flip_n(segs, round(temperature))\n",
    "            score = evaluate(text, guess)\n",
    "            if score < best:\n",
    "                best, best_segs = score, guess\n",
    "        score, segs = best, best_segs\n",
    "        \n",
    "        temperature = 55 / 1.2\n",
    "        \n",
    "        print(evaluate(text, segs), segment(text, segs))\n",
    "    print()\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouse', 'et', 'hek', 'ittyseet', 'hedoggy', 'doyoulik', 'et', 'hek', 'i', 'ttyliket', 'hedoggy']\n",
      "63 ['doyouse', 'et', 'hek', 'ittyseet', 'hedoggy', 'doyoulik', 'et', 'hek', 'i', 'ttyliket', 'hedoggy']\n",
      "62 ['doyo', 'u', 'se', 'et', 'heki', 'tty', 'se', 'et', 'hedoggy', 'doyoulik', 'et', 'heki', 'ttyliket', 'hedoggy']\n",
      "61 ['doy', 'o', 'u', 'se', 'et', 'heki', 'tty', 'se', 'et', 'hedoggy', 'doy', 'o', 'uli', 'k', 'et', 'heki', 'tty', 'li', 'k', 'et', 'hedoggy']\n",
      "61 ['doy', 'o', 'u', 'se', 'et', 'heki', 'tty', 'se', 'et', 'hedoggy', 'doy', 'o', 'uli', 'k', 'et', 'heki', 'tty', 'li', 'k', 'et', 'hedoggy']\n",
      "58 ['doy', 'o', 'u', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doy', 'o', 'uli', 'k', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "55 ['doy', 'o', 'u', 'se', 'ethekitty', 'se', 'et', 'hedoggy', 'doy', 'o', 'u', 'li', 'k', 'ethekitty', 'li', 'k', 'et', 'hedoggy']\n",
      "52 ['doy', 'o', 'u', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doy', 'o', 'u', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "52 ['doy', 'o', 'u', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doy', 'o', 'u', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "49 ['doyo', 'u', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyo', 'u', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "46 ['doyou', 'se', 'et', 'hekitty', 'se', 'et', 'hedoggy', 'doyou', 'lik', 'et', 'hekitty', 'lik', 'et', 'hedoggy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0000101010000001010100000010000100101000000100101000000'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "anneal(text, seg1, 5000, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
